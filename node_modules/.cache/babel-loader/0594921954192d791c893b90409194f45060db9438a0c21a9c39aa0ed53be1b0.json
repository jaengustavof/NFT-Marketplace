{"ast":null,"code":"import _classCallCheck from \"/home/gustavo/blockchain/Marketplace/node_modules/@babel/runtime/helpers/esm/classCallCheck.js\";\nimport _createClass from \"/home/gustavo/blockchain/Marketplace/node_modules/@babel/runtime/helpers/esm/createClass.js\";\nimport { decodeErrPrefix } from './common.js';\nimport { Type } from './token.js';\nimport { jump, quick } from './jump.js';\nvar defaultDecodeOptions = {\n  strict: false,\n  allowIndefinite: true,\n  allowUndefined: true,\n  allowBigInt: true\n};\nvar Tokeniser = /*#__PURE__*/function () {\n  function Tokeniser(data) {\n    var options = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n    _classCallCheck(this, Tokeniser);\n    this.pos = 0;\n    this.data = data;\n    this.options = options;\n  }\n  _createClass(Tokeniser, [{\n    key: \"done\",\n    value: function done() {\n      return this.pos >= this.data.length;\n    }\n  }, {\n    key: \"next\",\n    value: function next() {\n      var byt = this.data[this.pos];\n      var token = quick[byt];\n      if (token === undefined) {\n        var decoder = jump[byt];\n        if (!decoder) {\n          throw new Error(\"\".concat(decodeErrPrefix, \" no decoder for major type \").concat(byt >>> 5, \" (byte 0x\").concat(byt.toString(16).padStart(2, '0'), \")\"));\n        }\n        var minor = byt & 31;\n        token = decoder(this.data, this.pos, minor, this.options);\n      }\n      this.pos += token.encodedLength;\n      return token;\n    }\n  }]);\n  return Tokeniser;\n}();\nvar DONE = Symbol.for('DONE');\nvar BREAK = Symbol.for('BREAK');\nfunction tokenToArray(token, tokeniser, options) {\n  var arr = [];\n  for (var i = 0; i < token.value; i++) {\n    var value = tokensToObject(tokeniser, options);\n    if (value === BREAK) {\n      if (token.value === Infinity) {\n        break;\n      }\n      throw new Error(\"\".concat(decodeErrPrefix, \" got unexpected break to lengthed array\"));\n    }\n    if (value === DONE) {\n      throw new Error(\"\".concat(decodeErrPrefix, \" found array but not enough entries (got \").concat(i, \", expected \").concat(token.value, \")\"));\n    }\n    arr[i] = value;\n  }\n  return arr;\n}\nfunction tokenToMap(token, tokeniser, options) {\n  var useMaps = options.useMaps === true;\n  var obj = useMaps ? undefined : {};\n  var m = useMaps ? new Map() : undefined;\n  for (var i = 0; i < token.value; i++) {\n    var key = tokensToObject(tokeniser, options);\n    if (key === BREAK) {\n      if (token.value === Infinity) {\n        break;\n      }\n      throw new Error(\"\".concat(decodeErrPrefix, \" got unexpected break to lengthed map\"));\n    }\n    if (key === DONE) {\n      throw new Error(\"\".concat(decodeErrPrefix, \" found map but not enough entries (got \").concat(i, \" [no key], expected \").concat(token.value, \")\"));\n    }\n    if (useMaps !== true && typeof key !== 'string') {\n      throw new Error(\"\".concat(decodeErrPrefix, \" non-string keys not supported (got \").concat(typeof key, \")\"));\n    }\n    if (options.rejectDuplicateMapKeys === true) {\n      if (useMaps && m.has(key) || !useMaps && key in obj) {\n        throw new Error(\"\".concat(decodeErrPrefix, \" found repeat map key \\\"\").concat(key, \"\\\"\"));\n      }\n    }\n    var value = tokensToObject(tokeniser, options);\n    if (value === DONE) {\n      throw new Error(\"\".concat(decodeErrPrefix, \" found map but not enough entries (got \").concat(i, \" [no value], expected \").concat(token.value, \")\"));\n    }\n    if (useMaps) {\n      m.set(key, value);\n    } else {\n      obj[key] = value;\n    }\n  }\n  return useMaps ? m : obj;\n}\nfunction tokensToObject(tokeniser, options) {\n  if (tokeniser.done()) {\n    return DONE;\n  }\n  var token = tokeniser.next();\n  if (token.type === Type.break) {\n    return BREAK;\n  }\n  if (token.type.terminal) {\n    return token.value;\n  }\n  if (token.type === Type.array) {\n    return tokenToArray(token, tokeniser, options);\n  }\n  if (token.type === Type.map) {\n    return tokenToMap(token, tokeniser, options);\n  }\n  if (token.type === Type.tag) {\n    if (options.tags && typeof options.tags[token.value] === 'function') {\n      var tagged = tokensToObject(tokeniser, options);\n      return options.tags[token.value](tagged);\n    }\n    throw new Error(\"\".concat(decodeErrPrefix, \" tag not supported (\").concat(token.value, \")\"));\n  }\n  throw new Error('unsupported');\n}\nfunction decode(data, options) {\n  if (!(data instanceof Uint8Array)) {\n    throw new Error(\"\".concat(decodeErrPrefix, \" data to decode must be a Uint8Array\"));\n  }\n  options = Object.assign({}, defaultDecodeOptions, options);\n  var tokeniser = options.tokenizer || new Tokeniser(data, options);\n  var decoded = tokensToObject(tokeniser, options);\n  if (decoded === DONE) {\n    throw new Error(\"\".concat(decodeErrPrefix, \" did not find any content to decode\"));\n  }\n  if (decoded === BREAK) {\n    throw new Error(\"\".concat(decodeErrPrefix, \" got unexpected break\"));\n  }\n  if (!tokeniser.done()) {\n    throw new Error(\"\".concat(decodeErrPrefix, \" too many terminals, data makes no sense\"));\n  }\n  return decoded;\n}\nexport { Tokeniser, tokensToObject, decode };","map":{"version":3,"names":["decodeErrPrefix","Type","jump","quick","defaultDecodeOptions","strict","allowIndefinite","allowUndefined","allowBigInt","Tokeniser","data","options","arguments","length","undefined","_classCallCheck","pos","_createClass","key","value","done","next","byt","token","decoder","Error","concat","toString","padStart","minor","encodedLength","DONE","Symbol","for","BREAK","tokenToArray","tokeniser","arr","i","tokensToObject","Infinity","tokenToMap","useMaps","obj","m","Map","rejectDuplicateMapKeys","has","set","type","break","terminal","array","map","tag","tags","tagged","decode","Uint8Array","Object","assign","tokenizer","decoded"],"sources":["/home/gustavo/blockchain/Marketplace/node_modules/cborg/esm/lib/decode.js"],"sourcesContent":["import { decodeErrPrefix } from './common.js';\nimport { Type } from './token.js';\nimport {\n  jump,\n  quick\n} from './jump.js';\nconst defaultDecodeOptions = {\n  strict: false,\n  allowIndefinite: true,\n  allowUndefined: true,\n  allowBigInt: true\n};\nclass Tokeniser {\n  constructor(data, options = {}) {\n    this.pos = 0;\n    this.data = data;\n    this.options = options;\n  }\n  done() {\n    return this.pos >= this.data.length;\n  }\n  next() {\n    const byt = this.data[this.pos];\n    let token = quick[byt];\n    if (token === undefined) {\n      const decoder = jump[byt];\n      if (!decoder) {\n        throw new Error(`${ decodeErrPrefix } no decoder for major type ${ byt >>> 5 } (byte 0x${ byt.toString(16).padStart(2, '0') })`);\n      }\n      const minor = byt & 31;\n      token = decoder(this.data, this.pos, minor, this.options);\n    }\n    this.pos += token.encodedLength;\n    return token;\n  }\n}\nconst DONE = Symbol.for('DONE');\nconst BREAK = Symbol.for('BREAK');\nfunction tokenToArray(token, tokeniser, options) {\n  const arr = [];\n  for (let i = 0; i < token.value; i++) {\n    const value = tokensToObject(tokeniser, options);\n    if (value === BREAK) {\n      if (token.value === Infinity) {\n        break;\n      }\n      throw new Error(`${ decodeErrPrefix } got unexpected break to lengthed array`);\n    }\n    if (value === DONE) {\n      throw new Error(`${ decodeErrPrefix } found array but not enough entries (got ${ i }, expected ${ token.value })`);\n    }\n    arr[i] = value;\n  }\n  return arr;\n}\nfunction tokenToMap(token, tokeniser, options) {\n  const useMaps = options.useMaps === true;\n  const obj = useMaps ? undefined : {};\n  const m = useMaps ? new Map() : undefined;\n  for (let i = 0; i < token.value; i++) {\n    const key = tokensToObject(tokeniser, options);\n    if (key === BREAK) {\n      if (token.value === Infinity) {\n        break;\n      }\n      throw new Error(`${ decodeErrPrefix } got unexpected break to lengthed map`);\n    }\n    if (key === DONE) {\n      throw new Error(`${ decodeErrPrefix } found map but not enough entries (got ${ i } [no key], expected ${ token.value })`);\n    }\n    if (useMaps !== true && typeof key !== 'string') {\n      throw new Error(`${ decodeErrPrefix } non-string keys not supported (got ${ typeof key })`);\n    }\n    if (options.rejectDuplicateMapKeys === true) {\n      if (useMaps && m.has(key) || !useMaps && key in obj) {\n        throw new Error(`${ decodeErrPrefix } found repeat map key \"${ key }\"`);\n      }\n    }\n    const value = tokensToObject(tokeniser, options);\n    if (value === DONE) {\n      throw new Error(`${ decodeErrPrefix } found map but not enough entries (got ${ i } [no value], expected ${ token.value })`);\n    }\n    if (useMaps) {\n      m.set(key, value);\n    } else {\n      obj[key] = value;\n    }\n  }\n  return useMaps ? m : obj;\n}\nfunction tokensToObject(tokeniser, options) {\n  if (tokeniser.done()) {\n    return DONE;\n  }\n  const token = tokeniser.next();\n  if (token.type === Type.break) {\n    return BREAK;\n  }\n  if (token.type.terminal) {\n    return token.value;\n  }\n  if (token.type === Type.array) {\n    return tokenToArray(token, tokeniser, options);\n  }\n  if (token.type === Type.map) {\n    return tokenToMap(token, tokeniser, options);\n  }\n  if (token.type === Type.tag) {\n    if (options.tags && typeof options.tags[token.value] === 'function') {\n      const tagged = tokensToObject(tokeniser, options);\n      return options.tags[token.value](tagged);\n    }\n    throw new Error(`${ decodeErrPrefix } tag not supported (${ token.value })`);\n  }\n  throw new Error('unsupported');\n}\nfunction decode(data, options) {\n  if (!(data instanceof Uint8Array)) {\n    throw new Error(`${ decodeErrPrefix } data to decode must be a Uint8Array`);\n  }\n  options = Object.assign({}, defaultDecodeOptions, options);\n  const tokeniser = options.tokenizer || new Tokeniser(data, options);\n  const decoded = tokensToObject(tokeniser, options);\n  if (decoded === DONE) {\n    throw new Error(`${ decodeErrPrefix } did not find any content to decode`);\n  }\n  if (decoded === BREAK) {\n    throw new Error(`${ decodeErrPrefix } got unexpected break`);\n  }\n  if (!tokeniser.done()) {\n    throw new Error(`${ decodeErrPrefix } too many terminals, data makes no sense`);\n  }\n  return decoded;\n}\nexport {\n  Tokeniser,\n  tokensToObject,\n  decode\n};"],"mappings":";;AAAA,SAASA,eAAe,QAAQ,aAAa;AAC7C,SAASC,IAAI,QAAQ,YAAY;AACjC,SACEC,IAAI,EACJC,KAAK,QACA,WAAW;AAClB,IAAMC,oBAAoB,GAAG;EAC3BC,MAAM,EAAE,KAAK;EACbC,eAAe,EAAE,IAAI;EACrBC,cAAc,EAAE,IAAI;EACpBC,WAAW,EAAE;AACf,CAAC;AAAC,IACIC,SAAS;EACb,SAAAA,UAAYC,IAAI,EAAgB;IAAA,IAAdC,OAAO,GAAAC,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAG,CAAC,CAAC;IAAAG,eAAA,OAAAN,SAAA;IAC5B,IAAI,CAACO,GAAG,GAAG,CAAC;IACZ,IAAI,CAACN,IAAI,GAAGA,IAAI;IAChB,IAAI,CAACC,OAAO,GAAGA,OAAO;EACxB;EAACM,YAAA,CAAAR,SAAA;IAAAS,GAAA;IAAAC,KAAA,EACD,SAAAC,KAAA,EAAO;MACL,OAAO,IAAI,CAACJ,GAAG,IAAI,IAAI,CAACN,IAAI,CAACG,MAAM;IACrC;EAAC;IAAAK,GAAA;IAAAC,KAAA,EACD,SAAAE,KAAA,EAAO;MACL,IAAMC,GAAG,GAAG,IAAI,CAACZ,IAAI,CAAC,IAAI,CAACM,GAAG,CAAC;MAC/B,IAAIO,KAAK,GAAGpB,KAAK,CAACmB,GAAG,CAAC;MACtB,IAAIC,KAAK,KAAKT,SAAS,EAAE;QACvB,IAAMU,OAAO,GAAGtB,IAAI,CAACoB,GAAG,CAAC;QACzB,IAAI,CAACE,OAAO,EAAE;UACZ,MAAM,IAAIC,KAAK,IAAAC,MAAA,CAAK1B,eAAe,iCAAA0B,MAAA,CAAgCJ,GAAG,KAAK,CAAC,eAAAI,MAAA,CAAcJ,GAAG,CAACK,QAAQ,CAAC,EAAE,CAAC,CAACC,QAAQ,CAAC,CAAC,EAAE,GAAG,CAAC,MAAI,CAAC;QAClI;QACA,IAAMC,KAAK,GAAGP,GAAG,GAAG,EAAE;QACtBC,KAAK,GAAGC,OAAO,CAAC,IAAI,CAACd,IAAI,EAAE,IAAI,CAACM,GAAG,EAAEa,KAAK,EAAE,IAAI,CAAClB,OAAO,CAAC;MAC3D;MACA,IAAI,CAACK,GAAG,IAAIO,KAAK,CAACO,aAAa;MAC/B,OAAOP,KAAK;IACd;EAAC;EAAA,OAAAd,SAAA;AAAA;AAEH,IAAMsB,IAAI,GAAGC,MAAM,CAACC,GAAG,CAAC,MAAM,CAAC;AAC/B,IAAMC,KAAK,GAAGF,MAAM,CAACC,GAAG,CAAC,OAAO,CAAC;AACjC,SAASE,YAAYA,CAACZ,KAAK,EAAEa,SAAS,EAAEzB,OAAO,EAAE;EAC/C,IAAM0B,GAAG,GAAG,EAAE;EACd,KAAK,IAAIC,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGf,KAAK,CAACJ,KAAK,EAAEmB,CAAC,EAAE,EAAE;IACpC,IAAMnB,KAAK,GAAGoB,cAAc,CAACH,SAAS,EAAEzB,OAAO,CAAC;IAChD,IAAIQ,KAAK,KAAKe,KAAK,EAAE;MACnB,IAAIX,KAAK,CAACJ,KAAK,KAAKqB,QAAQ,EAAE;QAC5B;MACF;MACA,MAAM,IAAIf,KAAK,IAAAC,MAAA,CAAK1B,eAAe,4CAA0C,CAAC;IAChF;IACA,IAAImB,KAAK,KAAKY,IAAI,EAAE;MAClB,MAAM,IAAIN,KAAK,IAAAC,MAAA,CAAK1B,eAAe,+CAAA0B,MAAA,CAA8CY,CAAC,iBAAAZ,MAAA,CAAgBH,KAAK,CAACJ,KAAK,MAAI,CAAC;IACpH;IACAkB,GAAG,CAACC,CAAC,CAAC,GAAGnB,KAAK;EAChB;EACA,OAAOkB,GAAG;AACZ;AACA,SAASI,UAAUA,CAAClB,KAAK,EAAEa,SAAS,EAAEzB,OAAO,EAAE;EAC7C,IAAM+B,OAAO,GAAG/B,OAAO,CAAC+B,OAAO,KAAK,IAAI;EACxC,IAAMC,GAAG,GAAGD,OAAO,GAAG5B,SAAS,GAAG,CAAC,CAAC;EACpC,IAAM8B,CAAC,GAAGF,OAAO,GAAG,IAAIG,GAAG,CAAC,CAAC,GAAG/B,SAAS;EACzC,KAAK,IAAIwB,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGf,KAAK,CAACJ,KAAK,EAAEmB,CAAC,EAAE,EAAE;IACpC,IAAMpB,GAAG,GAAGqB,cAAc,CAACH,SAAS,EAAEzB,OAAO,CAAC;IAC9C,IAAIO,GAAG,KAAKgB,KAAK,EAAE;MACjB,IAAIX,KAAK,CAACJ,KAAK,KAAKqB,QAAQ,EAAE;QAC5B;MACF;MACA,MAAM,IAAIf,KAAK,IAAAC,MAAA,CAAK1B,eAAe,0CAAwC,CAAC;IAC9E;IACA,IAAIkB,GAAG,KAAKa,IAAI,EAAE;MAChB,MAAM,IAAIN,KAAK,IAAAC,MAAA,CAAK1B,eAAe,6CAAA0B,MAAA,CAA4CY,CAAC,0BAAAZ,MAAA,CAAyBH,KAAK,CAACJ,KAAK,MAAI,CAAC;IAC3H;IACA,IAAIuB,OAAO,KAAK,IAAI,IAAI,OAAOxB,GAAG,KAAK,QAAQ,EAAE;MAC/C,MAAM,IAAIO,KAAK,IAAAC,MAAA,CAAK1B,eAAe,0CAAA0B,MAAA,CAAyC,OAAOR,GAAG,MAAI,CAAC;IAC7F;IACA,IAAIP,OAAO,CAACmC,sBAAsB,KAAK,IAAI,EAAE;MAC3C,IAAIJ,OAAO,IAAIE,CAAC,CAACG,GAAG,CAAC7B,GAAG,CAAC,IAAI,CAACwB,OAAO,IAAIxB,GAAG,IAAIyB,GAAG,EAAE;QACnD,MAAM,IAAIlB,KAAK,IAAAC,MAAA,CAAK1B,eAAe,8BAAA0B,MAAA,CAA4BR,GAAG,OAAI,CAAC;MACzE;IACF;IACA,IAAMC,KAAK,GAAGoB,cAAc,CAACH,SAAS,EAAEzB,OAAO,CAAC;IAChD,IAAIQ,KAAK,KAAKY,IAAI,EAAE;MAClB,MAAM,IAAIN,KAAK,IAAAC,MAAA,CAAK1B,eAAe,6CAAA0B,MAAA,CAA4CY,CAAC,4BAAAZ,MAAA,CAA2BH,KAAK,CAACJ,KAAK,MAAI,CAAC;IAC7H;IACA,IAAIuB,OAAO,EAAE;MACXE,CAAC,CAACI,GAAG,CAAC9B,GAAG,EAAEC,KAAK,CAAC;IACnB,CAAC,MAAM;MACLwB,GAAG,CAACzB,GAAG,CAAC,GAAGC,KAAK;IAClB;EACF;EACA,OAAOuB,OAAO,GAAGE,CAAC,GAAGD,GAAG;AAC1B;AACA,SAASJ,cAAcA,CAACH,SAAS,EAAEzB,OAAO,EAAE;EAC1C,IAAIyB,SAAS,CAAChB,IAAI,CAAC,CAAC,EAAE;IACpB,OAAOW,IAAI;EACb;EACA,IAAMR,KAAK,GAAGa,SAAS,CAACf,IAAI,CAAC,CAAC;EAC9B,IAAIE,KAAK,CAAC0B,IAAI,KAAKhD,IAAI,CAACiD,KAAK,EAAE;IAC7B,OAAOhB,KAAK;EACd;EACA,IAAIX,KAAK,CAAC0B,IAAI,CAACE,QAAQ,EAAE;IACvB,OAAO5B,KAAK,CAACJ,KAAK;EACpB;EACA,IAAII,KAAK,CAAC0B,IAAI,KAAKhD,IAAI,CAACmD,KAAK,EAAE;IAC7B,OAAOjB,YAAY,CAACZ,KAAK,EAAEa,SAAS,EAAEzB,OAAO,CAAC;EAChD;EACA,IAAIY,KAAK,CAAC0B,IAAI,KAAKhD,IAAI,CAACoD,GAAG,EAAE;IAC3B,OAAOZ,UAAU,CAAClB,KAAK,EAAEa,SAAS,EAAEzB,OAAO,CAAC;EAC9C;EACA,IAAIY,KAAK,CAAC0B,IAAI,KAAKhD,IAAI,CAACqD,GAAG,EAAE;IAC3B,IAAI3C,OAAO,CAAC4C,IAAI,IAAI,OAAO5C,OAAO,CAAC4C,IAAI,CAAChC,KAAK,CAACJ,KAAK,CAAC,KAAK,UAAU,EAAE;MACnE,IAAMqC,MAAM,GAAGjB,cAAc,CAACH,SAAS,EAAEzB,OAAO,CAAC;MACjD,OAAOA,OAAO,CAAC4C,IAAI,CAAChC,KAAK,CAACJ,KAAK,CAAC,CAACqC,MAAM,CAAC;IAC1C;IACA,MAAM,IAAI/B,KAAK,IAAAC,MAAA,CAAK1B,eAAe,0BAAA0B,MAAA,CAAyBH,KAAK,CAACJ,KAAK,MAAI,CAAC;EAC9E;EACA,MAAM,IAAIM,KAAK,CAAC,aAAa,CAAC;AAChC;AACA,SAASgC,MAAMA,CAAC/C,IAAI,EAAEC,OAAO,EAAE;EAC7B,IAAI,EAAED,IAAI,YAAYgD,UAAU,CAAC,EAAE;IACjC,MAAM,IAAIjC,KAAK,IAAAC,MAAA,CAAK1B,eAAe,yCAAuC,CAAC;EAC7E;EACAW,OAAO,GAAGgD,MAAM,CAACC,MAAM,CAAC,CAAC,CAAC,EAAExD,oBAAoB,EAAEO,OAAO,CAAC;EAC1D,IAAMyB,SAAS,GAAGzB,OAAO,CAACkD,SAAS,IAAI,IAAIpD,SAAS,CAACC,IAAI,EAAEC,OAAO,CAAC;EACnE,IAAMmD,OAAO,GAAGvB,cAAc,CAACH,SAAS,EAAEzB,OAAO,CAAC;EAClD,IAAImD,OAAO,KAAK/B,IAAI,EAAE;IACpB,MAAM,IAAIN,KAAK,IAAAC,MAAA,CAAK1B,eAAe,wCAAsC,CAAC;EAC5E;EACA,IAAI8D,OAAO,KAAK5B,KAAK,EAAE;IACrB,MAAM,IAAIT,KAAK,IAAAC,MAAA,CAAK1B,eAAe,0BAAwB,CAAC;EAC9D;EACA,IAAI,CAACoC,SAAS,CAAChB,IAAI,CAAC,CAAC,EAAE;IACrB,MAAM,IAAIK,KAAK,IAAAC,MAAA,CAAK1B,eAAe,6CAA2C,CAAC;EACjF;EACA,OAAO8D,OAAO;AAChB;AACA,SACErD,SAAS,EACT8B,cAAc,EACdkB,MAAM"},"metadata":{},"sourceType":"module","externalDependencies":[]}